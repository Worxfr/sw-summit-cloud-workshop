AWSTemplateFormatVersion: "2010-09-09"
Transform: AWS::Serverless-2016-10-31
Description: AWS backend stack
Resources:
  ################# SNS,ES,S3 ################
  SWSNSTopic:
    Type: AWS::SNS::Topic
    Properties: 
      DisplayName: sw-notification-topic
      TopicName: sw-notification-topic
  S3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete
    Properties:
      BucketName: !Sub 'sw-backup-bucket-${AWS::Region}-${AWS::AccountId}'
  SWElasticSearch:
    Type: AWS::Elasticsearch::Domain
    Properties: 
      AccessPolicies:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            AWS: '*'
          Action:
          - 'es:ESHttp*'
          Resource: !Sub 'arn:aws:es:${AWS::Region}:${AWS::AccountId}:domain/sw-elasticsearch/*'
          Condition:
            IpAddress:
              aws:SourceIp: ["77.197.140.100/30"]  # Parameterize 
      DomainName: sw-elasticsearch
      ElasticsearchClusterConfig: 
        InstanceCount: "1"
        InstanceType: "m4.large.elasticsearch"
        DedicatedMasterEnabled: false
        ZoneAwarenessEnabled: false
      ElasticsearchVersion: "7.1"
      EBSOptions:
          EBSEnabled: true
          VolumeSize: 10
          VolumeType: "gp2"
  ################# API ######################
  APIRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: ''
            Effect: Allow
            Principal:
              Service: apigateway.amazonaws.com
            Action: 'sts:AssumeRole'
  APIPolicy:
    Type: AWS::IAM::Policy
    Properties:
      Roles:
        - !Ref APIRole
      PolicyName: api_delivery_policy
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - 'kinesis:*'
            Resource:
              - !GetAtt SWKinesisStream.Arn
  DeliveryApi:
    Type: AWS::Serverless::Api
    Properties:
      StageName: prod #!Ref ApiStageName
      DefinitionBody:
        swagger: "2.0"
        info:
          title: "Kinesis API"
        schemes: ["https"]
        paths:
          /streams/{stream-name}/record:
            put:
              consumes: ["application/json"]
              produces: ["application/json"]
              responses:
                "200":
                  description: "200 response"
                  schema:
                    $ref: "#/definitions/Empty"
              x-amazon-apigateway-integration:
                credentials: !GetAtt APIRole.Arn
                responses:
                  default:
                    statusCode: "200"
                requestParameters:
                  integration.request.header.Content-Type: "'application/x-amz-json-1.1'"
                uri: !Sub "arn:aws:apigateway:${AWS::Region}:kinesis:action/PutRecord"
                passthroughBehavior: "when_no_templates"
                httpMethod: "POST"
                requestTemplates:
                  application/json: !Sub >
                    {
                      "StreamName": "$input.params('stream-name')",
                      "Data": "$util.base64Encode($input.json('$.Data'))",
                      "PartitionKey": "$input.path('$.PartitionKey')"
                    }
                type: "aws"
            options:
              consumes: ["application/json"]
              produces: ["application/json"]
              responses:
                "200":
                  description: "200 response"
                  schema:
                    $ref: "#/definitions/Empty"
                  headers:
                    Access-Control-Allow-Origin:
                      type: "string"
                    Access-Control-Allow-Methods:
                      type: "string"
                    Access-Control-Allow-Headers:
                      type: "string"
              x-amazon-apigateway-integration:
                responses:
                  default:
                    statusCode: "200"
                    responseParameters:
                      method.response.header.Access-Control-Allow-Methods: "'DELETE,GET,HEAD,OPTIONS,PATCH,POST,PUT'"
                      method.response.header.Access-Control-Allow-Headers: "'Content-Type,Authorization,X-Amz-Date,X-Api-Key,X-Amz-Security-Token'"
                      method.response.header.Access-Control-Allow-Origin: "'*'"
                passthroughBehavior: "when_no_match"
                requestTemplates:
                  application/json: "{\"statusCode\": 200}"
                type: "mock"
        definitions:
          Empty:
            type: "object"
            title: "Empty Schema"
  ################# IAM ######################
  LambdaNotificationRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/AmazonSNSFullAccess"
      Policies:
        -
          PolicyName: "NotificationLogCreationPolicy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action: 
                  - "logs:CreateLogGroup"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"
        -
          PolicyName: "NotificationLogGenerationPolicy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action:
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/sw-lambda-notification:*"
        
      Path: "/service-role/"
      RoleName: "sw-lambda-notification-role"
  KinesisAnalyticsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "kinesisanalytics.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Policies:
        -
          PolicyName: "KinesisAnalyticsPolicy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Sid: "ReadInputKinesis"
                Effect: "Allow"
                Action: 
                  - "kinesis:DescribeStream"
                  - "kinesis:GetShardIterator"
                  - "kinesis:GetRecords"
                Resource: !GetAtt SWKinesisStream.Arn
              -
                Sid: ""
                Effect: "Allow"
                Action: 
                  - "lambda:InvokeFunction"
                  - "lambda:GetFunctionConfiguration"
                Resource: 
                  - !Join ["", [!GetAtt SWLambdaNotification.Arn, "*"]]
              -
                Sid: ""
                Effect: "Allow"
                Action: 
                  - "firehose:*"
                Resource: 
                  - !GetAtt SWKinesisDeliveryStream.Arn
      Path: "/"
      RoleName: "sw-kinesis-analytics-role"
  KinesisDeliveryRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "firehose.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Policies:
        -
          PolicyName: "KinesisDeliveryPolicy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Sid: ""
                Effect: "Allow"
                Action: 
                  - "s3:*"
                Resource:
                  - !GetAtt S3Bucket.Arn #"arn:aws:s3:::customers-shared-files-nd-sw"     # parameterize
                  - !Join ["/", [!GetAtt S3Bucket.Arn, "*"]] #"arn:aws:s3:::customers-shared-files-nd-sw/*"     # parameterize
              -
                Sid: ""
                Effect: "Allow"
                Action: 
                  - "lambda:InvokeFunction"
                  - "lambda:GetFunctionConfiguration"
                Resource: !Join ["", [!GetAtt SWLambdaNotification.Arn, "*"]]
              -
                Sid: ""
                Effect: "Allow"
                Action: 
                  - "es:DescribeElasticsearchDomain"
                  - "es:DescribeElasticsearchDomains"
                  - "es:DescribeElasticsearchDomainConfig"
                  - "es:ESHttpPost"
                  - "es:ESHttpPut"
                  - "es:ESHttpGet"
                Resource:
                  - !GetAtt SWElasticSearch.Arn
                  - !Join ["/", [!GetAtt SWElasticSearch.Arn, "*"]]
              -
                Sid: ""
                Effect: "Allow"
                Action: 
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/kinesisfirehose/sw-firehose-delivery:log-stream:*"
              -
                Sid: ""
                Effect: "Allow"
                Action: 
                  - "kinesis:DescribeStream"
                  - "kinesis:GetShardIterator"
                  - "kinesis:GetRecords"
                Resource: !GetAtt SWKinesisStream.Arn
              -
                Effect: "Allow"
                Action: 
                  - "kms:Decrypt"
                Resource: !Sub "arn:aws:kms:${AWS::Region}:${AWS::AccountId}:key/%SSE_KEY_ID%"
      Path: "/"
      RoleName: "sw-kinesis-delivery-role"
  ################# Simulator ################
  StepFunctionSimulatorRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "states.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AWSLambdaRole"
      Path: "/"
      RoleName: "sw-stepfunction-simulator-role"
  LambdaSimulatorRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "lambda.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Policies:
        -
          PolicyName: "SimulatorLogCreationPolicy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action: 
                  - "logs:CreateLogGroup"
                  - "logs:PutLogEvents"
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"    
      Path: "/service-role/"
      RoleName: "sw-lambda-simulator-role"
  StepFunctionsSimulatorStateMachine:
    Type: AWS::StepFunctions::StateMachine
    DependsOn: SWLambdaSimulator
    Properties:
      RoleArn: !GetAtt StepFunctionSimulatorRole.Arn
      DefinitionString: !Sub |-
        {
            "Comment": "Invoke Lambda every 2 seconds",
            "StartAt": "ConfigureCount",
            "States": {
                "ConfigureCount": {
                    "Type": "Pass",
                    "Result": {
                        "index": 0,
                        "count": 5000,
                        "step": 1
                    },
                    "ResultPath": "$.iterator",
                    "Next": "Iterator"
                },
                "Iterator": {
                    "Type": "Task",
                    "Resource": "${SWLambdaSimulator.Arn}",
                    "ResultPath": "$.iterator",
                    "Next": "IsCountReached"
                },
                "IsCountReached": {
                    "Type": "Choice",
                    "Choices": [
                        {
                            "Variable": "$.iterator.continue",
                            "BooleanEquals": true,
                            "Next": "Wait"
                        }
                    ],
                    "Default": "Done"
                },
                "Wait": {
                    "Type": "Wait",
                    "Seconds": 2,
                    "Next": "Iterator"
                },
                "Done": {
                    "Type": "Pass",
                    "End": true
                }
            }
        }
      StateMachineName: "sw-stepfunction-simulator"
  SWLambdaSimulator:
    Type: 'AWS::Serverless::Function'
    Properties:
      FunctionName: sw-lambda-device-simulator
      Handler: index.iterator
      Runtime: nodejs12.x
      InlineCode: !Sub "var https = require('https');\n
                        const deviceId = \"lambda-device\";\n
                        const temp_low = 30;\n
                        const temp_high = 38;\n
                        const acc_low = -1;\n
                        const acc_high = 1;\n
                        \n
                        function generate_query() {\n
                        \tvar light_low=parseInt(process.env.LIGHT_LOW);\n
                        \tvar light_high=parseInt(process.env.LIGHT_HIGH);\n
                        \t\tvar payload = {\n
                        \t\t\t\"Data\": {\n
                          \t\t\t\t\"deviceId\": deviceId.toString(),\n
                          \t\t\t\t\"light\": Math.floor(Math.random() * (light_high - light_low) + light_low),\n
                          \t\t\t\t\"accel\": {\n
                            \t\t\t\t\t\"x\": Math.random() * (acc_high - acc_low) + acc_low,\n
                            \t\t\t\t\t\"y\": Math.random() * (acc_high - acc_low) + acc_low,\n
                            \t\t\t\t\t\"z\": Math.random() * (acc_high - acc_low) + acc_low,\n
                            \t\t\t\t},\n
                            \t\t\t\t\"temp\": Math.random() * (temp_high - temp_low) + temp_low,\n
                            \t\t\t\t\"location\": \"48.875004,2.235794\",\n
                            \t\t\t\t\"creationDate\": Date.now(),\n
                            \t\t\t\t\"generatedDate\": Date.now()\n
                            \t\t\t},\n
                            \t\t\t\"PartitionKey\": 1\n
                            \t\t};\n
                            \tvar data = JSON.stringify(payload);\n
                            \n
                            \tconst options = {\n
                            \t\thostname: '${DeliveryApi}.execute-api.${AWS::Region}.amazonaws.com',\n
                            \t\tport: 443,\n
                            \t\tpath: '/prod/streams/sw-stream/record',\n
                            \t\tmethod: 'PUT',\n
                            \t\theaders: {\n
                              \t\t\t'Content-Type': 'application/json',\n
                              \t\t\t'Content-Length': data.length\n
                              \t\t}\n
                              \t};\n
                            
                              \tconst req = https.request(options, res => {\n
                              \n
                              \t\tres.on('data', d => {\n
                              \t\t\tprocess.stdout.write(d);\n
                              \t\t});\n
                              \t});\n
                            \n
                            \treq.on('error', error => {\n
                            \t\tconsole.error(error);\n
                            \t});\n
                            \n
                            \treq.write(data);\n
                            \treq.end();\n
                        }\n
                        \n
                        exports.iterator = function iterator (event, context, callback) {\n
                        \tlet index = event.iterator.index;\n
                        \tlet step = event.iterator.step;\n
                        \tlet count = event.iterator.count;\n
                            \n
                            \tgenerate_query();\n
                            \tindex += step;\n
                            \n
                            \tcallback(null, {\n
                            \t\tindex,\n
                            \t\tstep,\n
                            \t\tcount,\n
                            \t\tcontinue: index < count\n
                            \t});\n
                        };\n"
      MemorySize: 128
      Timeout: 10
      Environment:
        Variables:
          LIGHT_LOW: 1200
          LIGHT_HIGH: 1250
      Role: !GetAtt LambdaSimulatorRole.Arn
  ################# LAMBDA ###################
  SWLambdaNotification:
    Type: 'AWS::Serverless::Function'
    Properties:
      FunctionName: sw-lambda-notification
      Handler: index.handler
      Runtime: nodejs12.x
      InlineCode: !Sub " console.log('Loading function');\n
                      var AWS = require('aws-sdk');\n
                      var sns = new AWS.SNS();\n
                      exports.handler = async (event, context) => {\n
                          \tlet success = 0;\n
                          \tlet failure = 0;\n
                          \tconst output = event.records.map((record) => {\n
                              \t\t/* Data is base64 encoded, so decode here */\n
                              \t\tconst payload =Buffer.from(record.data, 'base64').toString();\n
                              \t\tconst recordData = JSON.parse(payload);\n
                              \t\tconsole.log(recordData.device_id.toString());\n
                              \t\ttry {\n
                                  \t\t\tvar params = {\n
                                      \t\t\t\tMessage: ('Something might be wrong with ' + recordData.device_id.toString()) ,\n
                                      \t\t\t\tSubject: 'Device Alarm',\n
                                      \t\t\t\tTopicArn: 'arn:aws:sns:${AWS::Region}:${AWS::AccountId}:sw-notification-topic'\n
                                    \t\t\t};\n
                                  \t\t\tconsole.log(params.Message.toString());\n
                                  \t\t\tsns.publish(params, context.done);\n
                                  \t\t\tsuccess++;\n
                                  \t\t\treturn {\n
                                      \t\t\t\trecordId: record.recordId,\n
                                      \t\t\t\tresult: 'Ok',\n
                                  \t\t\t};\n
                              \t\t} catch (err) {\n
                                  \t\t\tfailure++;\n
                                  \t\t\treturn {\n
                                      \t\t\t\trecordId: record.recordId,\n
                                      \t\t\t\tresult: 'DeliveryFailed',\n
                                  \t\t\t};\n
                              \t\t}\n
                          \t});\n
                          \treturn { records: output };\n
                      };\n
                    "
      MemorySize: 128
      Timeout: 3
      Role: !GetAtt LambdaNotificationRole.Arn
  ################# KINESIS ##################
  SWKinesisStream:
    Type: AWS::Kinesis::Stream
    Properties: 
      Name: sw-stream
      RetentionPeriodHours: 24
      ShardCount: 1
  SWKinesisDeliveryStream: 
    Type: AWS::KinesisFirehose::DeliveryStream
    Properties:
      DeliveryStreamName: sw-firehose-delivery
      DeliveryStreamType: DirectPut
      # KinesisStreamSourceConfiguration:
      #   KinesisStreamARN: !GetAtt SWKinesisStream.Arn
      #   RoleARN: !GetAtt KinesisDeliveryRole.Arn
      ElasticsearchDestinationConfiguration: 
        BufferingHints: 
          IntervalInSeconds: 60   #To parameterize
          SizeInMBs: 1
        CloudWatchLoggingOptions: 
          Enabled: false
        DomainARN: !GetAtt SWElasticSearch.Arn
        IndexName: "mangoh"
        IndexRotationPeriod: "NoRotation"
        TypeName: ""
        RetryOptions: 
          DurationInSeconds: 60
        RoleARN: !GetAtt KinesisDeliveryRole.Arn
        ProcessingConfiguration:
          Enabled: false
          # Processors:
          #   - Parameters:
          #       - ParameterName: LambdaArn
          #         ParameterValue: !GetAtt SWLambdaNotification.Arn 
          #     Type: Lambda 
        S3BackupMode: "AllDocuments"
        S3Configuration: 
          BucketARN: !GetAtt S3Bucket.Arn  # To parameterize
          BufferingHints: 
            IntervalInSeconds: 60
            SizeInMBs: 1
          CompressionFormat: "UNCOMPRESSED"
          Prefix: "sw-light/"
          RoleARN: !GetAtt KinesisDeliveryRole.Arn
          CloudWatchLoggingOptions: 
            Enabled: false
  SWKinesisDataAnalyticsApplication:
    Type: "AWS::KinesisAnalytics::Application"
    Properties:
      ApplicationName: sw-kinesis-data-analytics
      ApplicationCode: "
                        CREATE OR REPLACE STREAM \"TEMP_STREAM\" (\n
                          \"device_id\"      VARCHAR(32),\n
                          \"creation_date\"  TIMESTAMP,\n
                          \"generated_date\"  TIMESTAMP,\n
                          \"light_sensor\"   INTEGER,\n
                          \"acc_x\" DOUBLE,\n
                          \"acc_y\" DOUBLE,\n
                          \"acc_z\" DOUBLE,\n
                          \"temp_sensor\" DOUBLE,\n
                          \"location\" VARCHAR(128),\n
                          \"ANOMALY_SCORE\"  DOUBLE,\n
                          \"ANOMALY_EXPLANATION\" VARCHAR(20480));\n
                          -- Creates an output stream and defines a schema\n
                          CREATE OR REPLACE STREAM \"DESTINATION_SQL_STREAM\" (\n
                          \"device_id\"      VARCHAR(32),\n
                          \"creation_date\"  VARCHAR(20),\n
                          \"generated_date\"  VARCHAR(20),\n
                          \"light_sensor\"   INTEGER,\n
                          \"acc_x\" DOUBLE,\n
                          \"acc_y\" DOUBLE,\n
                          \"acc_z\" DOUBLE,\n
                          \"temp_sensor\" DOUBLE,\n
                          \"location\" VARCHAR(128),\n
                          \"ANOMALY_SCORE\"  DOUBLE,\n
                          \"ANOMALY_EXPLANATION\" VARCHAR(20480));\n
                          -- Creates an output stream for the alerting\n
                          CREATE OR REPLACE STREAM \"ANOMALY_SQL_STREAM\" (\n
                              \"device_id\"      VARCHAR(32),\n
                              \"creation_date\"  VARCHAR(20),\n
                              \"generated_date\"  VARCHAR(20),\n
                              \"ANOMALY_SCORE\"  DOUBLE);\n
                          \n
                          -- Compute an anomaly score for each record in the source stream\n
                          -- using Random Cut Forest\n
                          CREATE OR REPLACE PUMP \"STREAM_PUMP\" AS INSERT INTO \"TEMP_STREAM\"\n
                          SELECT STREAM\n
                              \"deviceId\" as \"device_id\",\n 
                              \"creationDate\" as \"creation_date\",\n 
                              \"generatedDate\" as \"generated_date\",\n 
                              \"light\" as \"light_sensor\",\n
                              \"x\" as \"acc_x\",\n
                              \"y\" as \"acc_y\",\n
                              \"z\" as \"acc_z\",\n
                              \"temp\" as \"temp_sensor\",\n
                              \"location\",\n
                              \"ANOMALY_SCORE\",\n
                              \"ANOMALY_EXPLANATION\" FROM TABLE(RANDOM_CUT_FOREST_WITH_EXPLANATION(CURSOR(\n
                                  SELECT STREAM \n
                                  \"deviceId\",\n
                                  TO_TIMESTAMP(\"creationDate\") as \"creationDate\",\n
                                  TO_TIMESTAMP(\"generatedDate\") as \"generatedDate\",\n
                                  \"light\",\n
                                  \"x\",\n
                                  \"y\",\n
                                  \"z\",\n
                                  \"temp\",\n
                                  \"location\"\n
                                  FROM \"SOURCE_SQL_STREAM_001\"), 10, 256, 10000, 10, true));\n
                                  
                          -- Sort records by descending anomaly score, insert into output stream\n
                          CREATE OR REPLACE PUMP \"OUTPUT_PUMP\" AS INSERT INTO \"DESTINATION_SQL_STREAM\"\n
                          SELECT STREAM\n
                              \"device_id\",\n
                              TIMESTAMP_TO_CHAR('yyyy-MM-dd', \"creation_date\")||'T'||TIMESTAMP_TO_CHAR('HH:mm:ss', \"creation_date\"),\n
                              TIMESTAMP_TO_CHAR('yyyy-MM-dd', \"generated_date\")||'T'||TIMESTAMP_TO_CHAR('HH:mm:ss', \"generated_date\"),\n
                              \"light_sensor\",\n
                              \"acc_x\",\n
                              \"acc_y\",\n
                              \"acc_z\",\n
                              \"temp_sensor\",\n
                              \"location\",\n
                              \"ANOMALY_SCORE\", \n
                              \"ANOMALY_EXPLANATION\"\n
                          FROM \"TEMP_STREAM\"\n
                          \n
                          -- Sort records by descending anomaly score, insert into output stream\n
                          CREATE OR REPLACE PUMP \"ALERT_PUMP\" AS INSERT INTO \"ANOMALY_SQL_STREAM\"\n
                              SELECT STREAM\n
                              \"device_id\",\n
                              TIMESTAMP_TO_CHAR('yyyy-MM-dd', \"creation_date\")||'T'||TIMESTAMP_TO_CHAR('HH:mm:ss', \"creation_date\"),\n
                              TIMESTAMP_TO_CHAR('yyyy-MM-dd', \"generated_date\")||'T'||TIMESTAMP_TO_CHAR('HH:mm:ss', \"generated_date\"),\n
                              \"ANOMALY_SCORE\"\n
                              FROM \"TEMP_STREAM\"\n
                              WHERE \"ANOMALY_SCORE\" > 4;\n
                        "
      Inputs:
        - NamePrefix: "SOURCE_SQL_STREAM"
          # InputProcessingConfiguration:
          #   InputLambdaProcessor:
          #     ResourceARN: !GetAtt SWLambdaTransformer.Arn 
          #     RoleARN: !GetAtt KinesisAnalyticsRole.Arn
          InputSchema:
            RecordColumns:
            - Name: "deviceId"
              SqlType: "VARCHAR(32)"
              Mapping: "$.deviceId"
            - Name: "light"
              SqlType: "INTEGER"
              Mapping: "$.light"
            - Name: "x"
              SqlType: "DOUBLE"
              Mapping: "$.accel.x"
            - Name: "y"
              SqlType: "DOUBLE"
              Mapping: "$.accel.y"
            - Name: "z"
              SqlType: "DOUBLE"
              Mapping: "$.accel.z"
            - Name: "temp"
              SqlType: "DOUBLE"
              Mapping: "$.temp"
            - Name: "location"
              SqlType: "VARCHAR(128)"
              Mapping: "$.location"
            - Name: "creationDate"
              SqlType: "BIGINT"
              Mapping: "$.creationDate"
            - Name: "generatedDate"
              SqlType: "BIGINT"
              Mapping: "$.generatedDate"
            RecordFormat:
              RecordFormatType: "JSON"
              MappingParameters:
                JSONMappingParameters:
                  RecordRowPath: "$"
            RecordEncoding: "UTF-8"
          KinesisStreamsInput:
            ResourceARN: !GetAtt SWKinesisStream.Arn
            RoleARN: !GetAtt KinesisAnalyticsRole.Arn
  SWKinesisDataAnalyticsApplicationOutput:
    Type: "AWS::KinesisAnalytics::ApplicationOutput"
    DependsOn: SWKinesisDataAnalyticsApplication
    Properties:
      ApplicationName: !Ref SWKinesisDataAnalyticsApplication
      Output:
        DestinationSchema:
          RecordFormatType: "JSON"
        KinesisFirehoseOutput:
          ResourceARN: !GetAtt SWKinesisDeliveryStream.Arn
          RoleARN: !GetAtt KinesisAnalyticsRole.Arn
        Name : "DESTINATION_SQL_STREAM"
Outputs:
  ProdDataEndpoint:
    Description: "API Prod stage endpoint"
    Value: !Sub "https://${DeliveryApi}.execute-api.${AWS::Region}.amazonaws.com/prod/"